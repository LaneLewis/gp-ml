import torch
from tqdm import tqdm
from utils.gaussian_process import sde_kernel_matrices
from utils.dummy_optimizer import DummyOptimizer
from utils.elbo_loss import approx_elbo_loss
from torch import optim

class GPML_VAE():
    def __init__(self,device:str,latent_dims:int,observation_dims:int,timesteps:int,
                 encoder_model:function,decoder_model:function,
                 signal_sds:list[float]=None, noise_sds:list[float]=None,
                 initial_taus:list[float]=None,initial_R_diag:list[float]=None)->object:
        '''
        Implements the GPML framework.
        device - torch device to use
        latent_dims - int specifying the number of latent dims (Z)
        observation_dims - int specifying the number of observation dims (X)
        timesteps - int specifying the number of timesteps in each observation (X)
        signal_sds - list of positive floats (size latent_dims) specifying the signal sd of the GP covariance
                    None initializes all parameters to 1.0 - 0.001
        noise_sds - list of positive floats (size latent_dims) specifying the signal sd of the GP covariance
                    None initializes all parameters to 0.001
        initial_taus - list of positive floats (size latent_dims) specifying the time constant of the GP covariance.
                       None initializes the parameters randomly
        initial_R_diag - list of positive floats (size latent_dims) specifying the diagonal noise of the observations (X)
        encoder_model - object with methods: .parameters() which returns the an iterator on the model parameters
                                             .forward(X) -> mu, Sigma. 
                                                This function takes data and returns the mean and covariance of a mv normal distribution.
                                                X has shape [batch_size,timesteps,observation_dims]
                                                mu has shape [batch_size,timesteps,latent_dims]
                                                Sigma has shape [batch_size,timesteps,latent_dims,latent_dims]
        decoder_model - .parameters() which returns the an iterator on the model parameters
                        .forward(Z) -> manifold_mean
                            This function takes in samples from the latent space and returns the mean
                            of the random manifold that the data is generated from.
                            Z has shape [batch_size,samples,timesteps,observation_dims]
        '''
        #initializes tau
        if initial_taus == None:
            self.taus = torch.rand((latent_dims),requires_grad=False,device=device)
        else:
            assert len(initial_taus) == latent_dims
            self.taus = torch.tensor(initial_taus,requires_grad=False,device=device)
        #initializes R
        if initial_R_diag== None:
            self.R_diag = torch.rand((timesteps),requires_grad=False,device=device)
        else:
            assert len(initial_R_diag) == observation_dims
            self.R_diag = torch.tensor(initial_R_diag,requires_grad=False,device=device)
        #initializes signal sds
        if signal_sds == None:
            self.signal_sds = (1.0 - 0.01)*torch.ones((timesteps),requires_grad=False,device=device)
        else:
            assert len(signal_sds) == latent_dims
            self.signal_sds = torch.tensor(initial_R_diag,requires_grad=False,device=device)
        #initializes noise_sds
        if noise_sds == None:
            self.noise_sds = 0.01*torch.ones((timesteps),requires_grad=False,device=device)
        else:
            assert len(noise_sds) == latent_dims
            self.noise_sds = torch.tensor(noise_sds,requires_grad=False,device=device)

        #builds all the passed internal variables
        self.encoder_model = encoder_model
        self.decoder_model = decoder_model
        self.observation_dims = observation_dims
        self.signal_sds = signal_sds
        self.noise_sds = noise_sds
        self.timesteps = timesteps
        #constructs the kernel matricies
        self.kernel_matrices = sde_kernel_matrices(timesteps,self.taus,self.signal_sds,self.noise_sds)
        self.training_loss = []

    def fit(self,X_train:torch.Tensor,encoder_optimizer:object=None,decoder_optimizer:object=None,epochs=100,
            lr=0.001,optimize_taus=True,optimize_R=True,batch_size=1,approx_elbo_loss_samples=100):
        '''
        X_train- tensor of shape (iid_samples,time_steps,observation_dims): Gives the training data consisting of 
                     data assumed to be generated by independent gaussian process latents with an sde kernel and then 
                     tranformed onto a nonlinear statistical manifold and then sampled from with a normal distribution.
        encoder_optimizer - optimizer object that implements the method .step() which is called after every batch: 
                            optimizer for the encoder model parameters.
        decoder_optimizer - optimizer object that implements the method .step() which is called after every batch:
                            optimizer for the encoder model parameters.
        optimize_taus - bool: indicates whether or not to run the optimizer on taus
        optimize_R - bool: indicates whether or not to run the optimizer on R
        batch_size - int: indicates the batch size to split the data into for each gradient step
        '''
        #constructs an optimizer for the parameters tau and R, makes a dummy optimizer if none is passed
        param_optimize_list = []
        if optimize_taus:
            self.taus.requires_grad = True
            param_optimize_list.append(self.taus)
        if optimize_R:
            self.R_diag.requires_grad = True
            param_optimize_list.append(self.taus)
        if len(param_optimize_list) > 0:
            param_optimizer = optim.Adam(param_optimize_list,lr=lr)
        else:
            param_optimizer = DummyOptimizer()
        #constructs an optimizer for the encoder parameters
        if encoder_optimizer == None:
            for param in self.encoder_model.parameters():
                param.requires_grad = False
            encoder_optimizer = DummyOptimizer()
        #constructs an optimizer for the decoder parameters
        if decoder_optimizer == None:
            for param in self.decoder_model.parameters():
                param.requires_grad = False
            decoder_optimizer = DummyOptimizer()

        #begins the main training loop
        batched_X_train = torch.DataLoader(torch.TensorDataset(X_train),batch_size=batch_size)
        for epoch in range(epochs):
            for batch_X in tqdm(batched_X_train,desc=f"epoch: {epoch}",colour="cyan"):
                encoder_optimizer.zero_grad()
                decoder_optimizer.zero_grad()
                param_optimizer.zero_grad()
                #computes the loss
                indiv_losses = approx_elbo_loss(batch_X,self.encoder_model.forward,self.decoder_model.forward,samples=approx_elbo_loss_samples)
                batch_loss = -1*torch.sum(indiv_losses)
                batch_loss.backward()
                #steps the grad
                encoder_optimizer.step()
                decoder_optimizer.step()
                param_optimizer.step()
                #training loss
                self.training_loss.append(batch_loss.detach().numpy())

                
